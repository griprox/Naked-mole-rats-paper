{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nakedmoleratvoices/Mole rats reborn/CodeRefactoredFinal\n"
     ]
    }
   ],
   "source": [
    "cd /home/nakedmoleratvoices/Mole\\ rats\\ reborn/CodeRefactoredFinal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from src.preprocessing.process_sounds_metadata import generate_sounds_metadata, make_fixed_size_sounds\n",
    "from src.preprocessing.filters import filter_recs_metadata\n",
    "from src.preprocessing.load_data import load_recs_dict, load_sounds\n",
    "from src.deep_learning.create_model import create_conv_model\n",
    "from src.data_representations.process_wavs import *\n",
    "from src.data_representations.process_images import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_recordings_metadata = '/home/nakedmoleratvoices/Mole rats reborn/CodeRefactoredFinal/data/'\n",
    "recordings_metadata_name = 'recordings_metadata.csv'\n",
    "\n",
    "# what data to load\n",
    "dates = 'all'\n",
    "colonies = 'all'\n",
    "experiments = 'all'\n",
    "stages = ['traced and checked', 'traced', 'labeled and checked']\n",
    "\n",
    "#?\n",
    "goodrec = 'baratheon_20-04-20_4012_0000029.npy'\n",
    "badrec = 'baratheon_11-04-20_2131_9460_0000023.npy'\n",
    "\n",
    "#!\n",
    "class_augment_dict = {'sound' : 3,  'noise' : 3}\n",
    "sounds_max_length = 10000\n",
    "sounds_min_length = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/expressions.py:193: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  op=op_str, alt_op=unsupported[op_str]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softchirp          68137\n",
      "noise              42604\n",
      "weirdo              7790\n",
      "grunt               3275\n",
      "loudchirp           2237\n",
      "downsweep           1827\n",
      "upsweep              718\n",
      "whistle              524\n",
      "combotwo             475\n",
      "combo                367\n",
      "scream               202\n",
      "mordent               19\n",
      "invertedmordent       10\n",
      "vtrill                 6\n",
      "Name: cl, dtype: int64\n",
      "noise    39980\n",
      "sound    36025\n",
      "Name: cl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "recs_metadata = pd.read_csv(path_to_recordings_metadata + recordings_metadata_name)\n",
    "mask = filter_recs_metadata(recs_metadata, dates, colonies, stages, experiments)\n",
    "recs_for_training = recs_metadata[mask]\n",
    "recs_dict = load_recs_dict(recs_for_training)\n",
    "sounds_metadata = generate_sounds_metadata(recs_for_training).reset_index(drop = True)\n",
    "print(sounds_metadata['cl'].value_counts())\n",
    "\n",
    "# drop some softchirp for the sake of class balancing\n",
    "max_softchirps = 22000\n",
    "softchirps_inds = np.where(sounds_metadata['cl'] == 'softchirp')[0]\n",
    "np.random.shuffle(softchirps_inds)\n",
    "sounds_metadata = sounds_metadata.drop(softchirps_inds[max_softchirps :]).reset_index(drop = True)\n",
    "sounds_metadata['cl'] = sounds_metadata['cl'].apply(lambda x : 'noise' if x == 'noise' else 'sound' )\n",
    "\n",
    "lengths = 22050 * (sounds_metadata['e'] - sounds_metadata['s'])\n",
    "mask_normal_sounds = (lengths >= sounds_min_length) & (lengths <= sounds_max_length)\n",
    "sounds_metadata = sounds_metadata[mask_normal_sounds].reset_index(drop = True)\n",
    "print(sounds_metadata['cl'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resolution = 1024 # ~0.05 sec\n",
    "step = 512 # ~0.025 sec\n",
    "\n",
    "sound_processing = {'stretching_lim_train' : None,\n",
    "                    'stretching_lim_test' : None,\n",
    "                    'noise_lim_train' : (0.001, 0.005),\n",
    "                    'noise_lim_test' : None,\n",
    "                    'filtering_th' : 3000\n",
    "                   }\n",
    "n_fft = 512\n",
    "n_mel = 80\n",
    "\n",
    "sounds_metadata_ints_split = make_fixed_size_sounds(sounds_metadata, resolution, step)\n",
    "sounds_npy_split = load_sounds(sounds_metadata_ints_split, recs_dict, noisy_sampling = False, timestamps = 'int')\n",
    "sounds_npy_pr_iterator = process_waves(sounds_npy_split, sound_processing['stretching_lim_train'],\n",
    "                                       sound_processing['noise_lim_train'], sound_processing['filtering_th'])\n",
    "melspecs_array = np.array(extract_melspecs(sounds_npy_pr_iterator, n_fft, n_mel))\n",
    "\n",
    "img_shape = melspecs_array[0].shape\n",
    "all_classes = ['noise', 'sound']\n",
    "y_train_num = np.array([all_classes.index(yi) for yi in sounds_metadata_ints_split['cl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 80, 3, 256)        2560      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 40, 3, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 40, 3, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 40, 3, 256)        590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 20, 3, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20, 3, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              15729664  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 17,373,954\n",
      "Trainable params: 17,373,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_conv_model(img_shape, all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1972/1972 [==============================] - 1683s 854ms/step - loss: 0.5124 - sparse_categorical_accuracy: 0.7480\n",
      "Epoch 2/5\n",
      "1972/1972 [==============================] - 1672s 848ms/step - loss: 0.3828 - sparse_categorical_accuracy: 0.8249\n",
      "Epoch 3/5\n",
      "1972/1972 [==============================] - 1670s 847ms/step - loss: 0.3637 - sparse_categorical_accuracy: 0.8358\n",
      "Epoch 4/5\n",
      "1972/1972 [==============================] - 1664s 844ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "1972/1972 [==============================] - 1683s 854ms/step - loss: 0.3470 - sparse_categorical_accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabec05c5c0>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(melspecs_array.reshape((*melspecs_array.shape, 1)), y_train_num, epochs = 2, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nakedmoleratvoices/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/splitter/deep_splitter/80x1024.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/splitter/deep_splitter/80x1024.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
